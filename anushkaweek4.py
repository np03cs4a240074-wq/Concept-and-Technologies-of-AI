# -*- coding: utf-8 -*-
"""AnushkaWeek4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N7M3R7AwJTNYCq1XDafFMB3hz1f1P6lw

# Mathematical Example of KNN Algorithm

We have the following training dataset:

| Point (X) | Class (y) |
|-----------|------------|
| (1, 1)    | 0 |
| (2, 2)    | 0 |
| (8, 8)    | 1 |
| (9, 9)    | 1 |

We want to classify the query point:

\[
Q = (3, 3)
\]

We will use **K = 3**.

---

## Step 1: Compute Euclidean Distances

Formula:

$$
d = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}
$$

### Distances from Q to each point:

- To (1,1):  
$$
d_1 = \sqrt{(3-1)^2 + (3-1)^2} = \sqrt{8} \approx 2.83
$$

- To (2,2):  
$$
d_2 = \sqrt{(3-2)^2 + (3-2)^2} = \sqrt{2} \approx 1.41
$$

- To (8,8):  
$$
d_3 = \sqrt{(3-8)^2 + (3-8)^2} = \sqrt{50} \approx 7.07
$$

- To (9,9):  
$$
d_4 = \sqrt{(3-9)^2 + (3-9)^2} = \sqrt{72} \approx 8.49
$$

---

## Step 2: Sort Distances (Smallest First)

| Point | Class | Distance |
|--------|---------|------------|
| (2,2) | 0 | **1.41** |
| (1,1) | 0 | **2.83** |
| (8,8) | 1 | 7.07 |
| (9,9) | 1 | 8.49 |

---

## Step 3: Pick k = 3 Nearest Neighbors

Nearest three points:

1. (2,2) → class 0  
2. (1,1) → class 0  
3. (8,8) → class 1  

---

## Step 4: Majority Voting

Classes of nearest neighbors:

\[
[0, 0, 1]
\]

Count:
- Class 0 → **2 votes**
- Class 1 → **1 vote**

Majority = **0**

---

# Final Prediction
$\boxed{\text{Predicted class for } Q = (3,3) \text{ is } 0}$
"""

import pandas as pd
import numpy as np

data = pd.read_csv("/content/drive/MyDrive/Concept and Technology of AI/titanic.csv")
data.head()

data.info()

categorical_columns = data.select_dtypes(include=['object']).columns

data = data.drop(columns=[col for col in categorical_columns if col != 'Survived'])

data.head()

missing_info = data.isnull().sum() / len(data) * 100
missing_info

for column in data.columns:
    if missing_info[column] > 10:
        data[column].fillna(data[column].mean(), inplace=True)
    else:
        data.dropna(subset=[column], inplace=True)

print("Data after processing:\n", data.head())
print("\nMissing values after processing:\n", data.isnull().sum())

X = data.drop(columns=['Survived']).values
y = data['Survived'].values


def train_test_split_scratch(X, y, test_size=0.3, random_seed=42):
    """
    Splits dataset into train and test sets.

    Arguments:
    X : np.ndarray
        Feature matrix.
    y : np.ndarray
        Target array.
    test_size : float
        Proportion of the dataset to include in the test split (0 < test_size < 1).
    random_seed : int
        Seed for reproducibility.

    Returns:
    X_train, X_test, y_train, y_test : np.ndarray
        Training and testing splits of features and target.
    """
    np.random.seed(random_seed)
    indices = np.arange(X.shape[0])
    np.random.shuffle(indices)

    test_split_size = int(len(X) * test_size)
    test_indices = indices[:test_split_size]
    train_indices = indices[test_split_size:]

    X_train, X_test = X[train_indices], X[test_indices]
    y_train, y_test = y[train_indices], y[test_indices]

    return X_train, X_test, y_train, y_test


X_train, X_test, y_train, y_test = train_test_split_scratch(X, y, test_size=0.3)


print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

def euclidean_distance(point1, point2):
    """
    Calculate the Euclidean distance between two points in n-dimensional space.

    Arguments:
    point1 : np.ndarray
        The first point as a numpy array.
    point2 : np.ndarray
        The second point as a numpy array.

    Returns:
    float
        The Euclidean distance between the two points.

    Raises:
    ValueError: If the input points do not have the same dimensionality.
    """

    if point1.shape != point2.shape:
        raise ValueError("Points must have the same dimensions to calculate Euclidean distance.")


    distance = np.sqrt(np.sum((point1 - point2) ** 2))
    return distance

try:

    point1 = np.array([3, 4])
    point2 = np.array([0, 0])


    result = euclidean_distance(point1, point2)


    expected_result = 5.0
    assert np.isclose(result, expected_result), f"Expected {expected_result}, but got {result}"

    print("Test passed successfully!")
except ValueError as ve:
    print(f"ValueError: {ve}")
except AssertionError as ae:
    print(f"AssertionError: {ae}")
except Exception as e:
    print(f"An unexpected error occurred: {e}")

def knn_predict_single(query, X_train, y_train, k=3):
    """
    Predict the class label for a single query using the K-nearest neighbors algorithm.

    Arguments:
    query : np.ndarray
        The query point for which the prediction is to be made.
    X_train : np.ndarray
        The training feature matrix.
    y_train : np.ndarray
        The training labels.
    k : int, optional
        The number of nearest neighbors to consider (default is 3).

    Returns:
    int
        The predicted class label for the query.
    """

    distances = [euclidean_distance(query, x) for x in X_train]


    sorted_indices = np.argsort(distances)


    nearest_indices = sorted_indices[:k]


    nearest_labels = y_train[nearest_indices]


    prediction = np.bincount(nearest_labels).argmax()

    return prediction

def knn_predict(X_test, X_train, y_train, k=3):
    """
    Predict the class labels for all test samples using the K-nearest neighbors algorithm.

    Arguments:
    X_test : np.ndarray
        The test feature matrix.
    X_train : np.ndarray
        The training feature matrix.
    y_train : np.ndarray
        The training labels.
    k : int, optional
        The number of nearest neighbors to consider (default is 3).

    Returns:
    np.ndarray
        An array of predicted class labels for the test samples.
    """

    predictions = [knn_predict_single(x, X_train, y_train, k) for x in X_test]
    return np.array(predictions)

try:

    X_test_sample = X_test[:5]
    y_test_sample = y_test[:5]


    predictions = knn_predict(X_test_sample, X_train, y_train, k=3)


    print("Predictions:", predictions)
    print("Actual labels:", y_test_sample)


    assert predictions.shape == y_test_sample.shape, (
        "The shape of predictions does not match the shape of the actual labels."
    )

    print("Test case passed successfully!")
except AssertionError as ae:
    print(f"AssertionError: {ae}")
except Exception as e:
    print(f"An unexpected error occurred: {e}")

def compute_accuracy(y_true, y_pred):
    """
    Compute the accuracy of predictions.

    Arguments:
    y_true : np.ndarray
        The true labels.
    y_pred : np.ndarray
        The predicted labels.

    Returns:
    float
        The accuracy as a percentage (0 to 100).
    """
    correct_predictions = np.sum(y_true == y_pred)
    total_predictions = len(y_true)
    accuracy = (correct_predictions / total_predictions) * 100
    return accuracy



try:

    predictions = knn_predict(X_test, X_train, y_train, k=3)


    accuracy = compute_accuracy(y_test, predictions)


    print(f"Accuracy of the KNN model on the test set: {accuracy:.2f}%")
except Exception as e:
    print(f"An unexpected error occurred during prediction or accuracy computation: {e}")

import matplotlib.pyplot as plt
def experiment_knn_k_values(X_train, y_train, X_test, y_test, k_values):
    """
    Run KNN predictions for different values of k and plot the accuracies.

    Arguments:
    X_train : np.ndarray
        The training feature matrix.
    y_train : np.ndarray
        The training labels.
    X_test : np.ndarray
        The test feature matrix.
    y_test : np.ndarray
        The test labels.
    k_values : list of int
        A list of k values to experiment with.

    Returns:
    dict
        A dictionary with k values as keys and their corresponding accuracies as values.
    """
    accuracies = {}

    for k in k_values:

        predictions = knn_predict(X_test, X_train, y_train, k=k)


        accuracy = compute_accuracy(y_test, predictions)
        accuracies[k] = accuracy

        print(f"Accuracy for k={k}: {accuracy:.2f}%")


    plt.figure(figsize=(10, 5))
    plt.plot(k_values, list(accuracies.values()), marker='o')
    plt.xlabel('k (Number of Neighbors)')
    plt.ylabel('Accuracy (%)')
    plt.title('Accuracy of KNN with Different Values of k')
    plt.grid(True)
    plt.show()

    return accuracies


k_values = range(1, 21)


try:
    accuracies = experiment_knn_k_values(X_train, y_train, X_test, y_test, k_values)
    print("Experiment completed. Check the plot for the accuracy trend.")
except Exception as e:
    print(f"An unexpected error occurred during the experiment: {e}")

